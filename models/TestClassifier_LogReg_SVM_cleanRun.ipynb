{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Pipeline Preparation\n",
    "Follow the instructions below to help you create your ML pipeline.\n",
    "### 1. Import libraries and load data from database.\n",
    "- Import Python libraries\n",
    "- Load dataset from database with [`read_sql_table`](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_sql_table.html)\n",
    "- Define feature and target variables X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import sys\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "stop_words = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from database\n",
    "engine = create_engine(\"sqlite:///../data/DisasterResponse.db\")\n",
    "\n",
    "connection = engine.connect()\n",
    "\n",
    "query = \"SELECT * FROM DisasterResponse\"  ## limit 1000 WHERE related <> 2\n",
    "df = pd.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the size of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get Summary stats on the data\n",
    "df.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find if there are response variables that have less than 2 values (0 or 1), that can be dropped from the\n",
    "\n",
    "# Build SQL that will give count of distinct values in the response column\n",
    "q2 = \"SELECT 'related                 '  AS COL , COUNT(distinct related) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'request' AS COL , COUNT(distinct request) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'offer' AS COL , COUNT(distinct offer) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'aid_related' AS COL , COUNT(distinct aid_related) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'medical_help' AS COL , COUNT(distinct medical_help) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'medical_products' AS COL , COUNT(distinct medical_products) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'search_and_rescue' AS COL , COUNT(distinct search_and_rescue) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'security' AS COL , COUNT(distinct security) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'military' AS COL , COUNT(distinct military) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'child_alone' AS COL , COUNT(distinct child_alone) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'water' AS COL , COUNT(distinct water) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'food' AS COL , COUNT(distinct food) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'shelter' AS COL , COUNT(distinct shelter) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'clothing' AS COL , COUNT(distinct clothing) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'money' AS COL , COUNT(distinct money) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'missing_people' AS COL , COUNT(distinct missing_people) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'refugees' AS COL , COUNT(distinct refugees) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'death' AS COL , COUNT(distinct death) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'other_aid' AS COL , COUNT(distinct other_aid) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'infrastructure_related' AS COL , COUNT(distinct infrastructure_related) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'transport' AS COL , COUNT(distinct transport) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'buildings' AS COL , COUNT(distinct buildings) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'electricity' AS COL , COUNT(distinct electricity) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'tools' AS COL , COUNT(distinct tools) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'hospitals' AS COL , COUNT(distinct hospitals) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'shops' AS COL , COUNT(distinct shops) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'aid_centers' AS COL , COUNT(distinct aid_centers) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'other_infrastructure' AS COL , COUNT(distinct other_infrastructure) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'weather_related' AS COL , COUNT(distinct weather_related) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'floods' AS COL , COUNT(distinct floods) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'storm' AS COL , COUNT(distinct storm) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'fire' AS COL , COUNT(distinct fire) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'earthquake' AS COL , COUNT(distinct earthquake) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'cold' AS COL , COUNT(distinct cold) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'other_weather' AS COL , COUNT(distinct other_weather) AS KNT FROM DisasterResponse GROUP BY 1 UNION SELECT 'direct_report' AS COL , COUNT(distinct direct_report) AS KNT FROM DisasterResponse GROUP BY 1 \"\n",
    "\n",
    "# Execute the SQL\n",
    "dfq2 = pd.read_sql(q2, connection)\n",
    "connection.close()\n",
    "\n",
    "# Show response variables that have less than 2 values (0 or 1)\n",
    "dfq2[dfq2[\"KNT\"] < 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## see the distribution of\n",
    "# df1 = df.loc[:, ~df.columns.isin(['id','message','original', 'genre','child_alone'])]\n",
    "# df1col = df1.columns\n",
    "# for col in df1col:\n",
    "#     print(col , \"==\\n\", df1[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep only the predictors in the X\n",
    "predictors = [\"message\"]\n",
    "\n",
    "X = df[predictors].message.values\n",
    "print(\"Dimensions of X are:\", X.ndim)\n",
    "print(\"Shape of X is\", X.shape)\n",
    "print(\"Size of X is\", X.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep ony the 35 response variables in y; dropped child_alone since all values are 0\n",
    "y = df.loc[:, ~df.columns.\n",
    "           isin(['id', 'message', 'original', 'genre', 'child_alone'])]\n",
    "y.head()\n",
    "print(\"Dimensions of y are:\", y.ndim)\n",
    "print(\"Shape of y is\", y.shape)\n",
    "print(\"Size of y is\", y.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Write a tokenization function to process your text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    \"\"\"\n",
    "    Tokenize text by removing punctuation, converting to lowercase, removing stop words, and lemmatizing.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text to be tokenized.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of clean tokens.\n",
    "    \"\"\"\n",
    "    # Normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words and lemmatize\n",
    "    tokens = [w for w in tokens if w not in stopwords.words(\"english\")]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the tokenize function\n",
    "for i in range(26, 29):  # (X.shape[0]):\n",
    "    LL = str(X[i])\n",
    "    print(tokenize(LL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build a machine learning pipeline\n",
    "This machine pipeline should take in the `message` column as input and output classification results on the other 36 categories in the dataset. You may find the [MultiOutputClassifier](http://scikit-learn.org/stable/modules/generated/sklearn.multioutput.MultiOutputClassifier.html) helpful for predicting multiple target variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipline\n",
    "logreg = LogisticRegression()  # multi_class='ovr')\n",
    "\n",
    "pipeline = Pipeline([('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultiOutputClassifier(logreg))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Train pipeline\n",
    "- Split data into train and test sets\n",
    "- Train pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's split the data as train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    train_size=0.75,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check the train test split results\n",
    "print(\"X_train Dim are:\", X_train.ndim, \"Shape=\", X_train.shape, \"Size =\",\n",
    "      X_train.size)\n",
    "print(\"y_train Dim are:\", y_train.ndim, \"Shape=\", y_train.shape, \"Size =\",\n",
    "      y_train.size)\n",
    "print(\"X_test  Dim are:\", X_test.ndim, \"Shape=\", X_test.shape, \"Size =\",\n",
    "      X_test.size)\n",
    "print(\"y_test  Dim are:\", y_test.ndim, \"Shape=\", y_test.shape, \"Size =\",\n",
    "      y_test.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the tokenize function on X_test\n",
    "for i in range(96, 100):  # (X.shape[0]):\n",
    "    LL = str(X_test[i])\n",
    "    print(tokenize(LL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the pipeline to your training data\n",
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Test your model\n",
    "Report the f1 score, precision and recall for each output category of the dataset. You can do this by iterating through the columns and calling sklearn's `classification_report` on each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the pipeline to make predictions on your test data\n",
    "y_pred = pipeline.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification Report for reponse variable\n",
    "i = 0\n",
    "for col in y_test.columns:\n",
    "    print(\n",
    "        \"\\n--------------Classification Report for reponse variable#{}. {} ----------------\"\n",
    "        .format(i, col))\n",
    "    print(classification_report(y_test[col], y_pred[:, i], zero_division=0))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion_matrix for reponse variables\n",
    "i = 0\n",
    "for col in y_test.columns:\n",
    "    cm = confusion_matrix(y_test[col],\n",
    "                          y_pred[:, i],\n",
    "                          labels=pipeline.classes_[i])\n",
    "    fig, ax = plt.subplots()\n",
    "    ConfusionMatrixDisplay(cm, display_labels=pipeline.classes_[i]).plot(ax=ax)\n",
    "    ax.set_title(f\"Confusion Matrix for {col}\")\n",
    "    i += 1\n",
    "    \n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visual representation of the pipeline in a html file\n",
    "from sklearn.utils import estimator_html_repr\n",
    "with open('my_estimator.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(estimator_html_repr(pipeline))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Improve your model\n",
    "Use grid search to find better parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's see what parms can be tuned\n",
    "pipeline.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'clf__estimator__multi_class': ['ovr'],\n",
    "    'clf__estimator__solver':\n",
    "    ['saga'],  # Algorithm to use in the optimization problem\n",
    "    'clf__estimator__n_jobs':\n",
    "    [2],  # Number of CPU cores used when parallelizing over classes\n",
    "    'clf__estimator__warm_start': [\n",
    "        True\n",
    "    ],  # When set to True, reuse the solution of the previous call to fit as initialization'\n",
    "    'clf__estimator__penalty': ['l2', 'elasticnet'],\n",
    "    'clf__estimator__verbose': [1]\n",
    "}\n",
    "\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "#    'multi_class' : ['ovr']   # not a choice\n",
    "#    'clf__random_state' : [0],# Used when solver == ‘sag’, ‘saga’ or ‘liblinear’ to shuffle the data.\n",
    "#    'clf__solver' : ['lbfgs','saga'],\n",
    "#    'clf__n_jobs' : [2,4],        # Number of CPU cores used when parallelizing over classes if multi_class=’ovr’”\n",
    "#    'clf__max_iter' : [500, 1000], # Maximum number of iterations taken for the solvers to converge\n",
    "#    'clf__penalty' :  ['l1', 'l2','elasticnet'],\n",
    "#    'clf__warm_start' : [True, False]           # When set to True, reuse the solution of the previous call to fit as initialization\n",
    "# , random_state=0,n_jobs = 2, max_iter=1000, C=1, penalty='l2')\n",
    "#     'vect__ngram_range' : [(1, 1), (1,2)],      # The lower and upper boundary of the range of n-values for different word n-grams\n",
    "#   'tfidf__smooth_idf' : [True, False], #Smooth idf weights by adding one to document frequencies, as if an extra document was seen containing every term in the collection exactly once. Prevents zero divisions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "5 fits failed out of a total of 10.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "5 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\", line 434, in fit\n",
      "    super().fit(X, Y, sample_weight, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\", line 202, in fit\n",
      "    self.estimators_ = Parallel(n_jobs=self.n_jobs)(\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\multioutput.py\", line 44, in _fit_estimator\n",
      "    estimator.fit(X, y, **fit_params)\n",
      "  File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1471, in fit\n",
      "    raise ValueError(\n",
      "ValueError: l1_ratio must be between 0 and 1; got (l1_ratio=None)\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.27682892        nan]\n",
      "  warnings.warn(\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   3 out of   3 | elapsed:    6.5s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    1.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=2)]: Using backend LokyBackend with 2 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "execution time for the fit= 2998089.579820633 milliseconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done   1 out of   1 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Let's run the GridSearch and compute elapsed time for the fit\n",
    "starttm = time.time()\n",
    "\n",
    "cv.fit(X_train, y_train)\n",
    "\n",
    "endtm = time.time()\n",
    "\n",
    "execTmsec = (endtm - starttm) * 10**3\n",
    "\n",
    "print(\"execution time for the fit=\", execTmsec, \"milliseconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__estimator__multi_class': 'ovr',\n",
       " 'clf__estimator__n_jobs': 2,\n",
       " 'clf__estimator__penalty': 'l2',\n",
       " 'clf__estimator__solver': 'saga',\n",
       " 'clf__estimator__verbose': 1,\n",
       " 'clf__estimator__warm_start': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what are the best parms\n",
    "cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([247.44829483, 231.23097219]),\n",
       " 'std_fit_time': array([4.44388587, 3.2594798 ]),\n",
       " 'mean_score_time': array([57.86113458,  0.        ]),\n",
       " 'std_score_time': array([0.70206072, 0.        ]),\n",
       " 'param_clf__estimator__multi_class': masked_array(data=['ovr', 'ovr'],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__n_jobs': masked_array(data=[2, 2],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__penalty': masked_array(data=['l2', 'elasticnet'],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__solver': masked_array(data=['saga', 'saga'],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__verbose': masked_array(data=[1, 1],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_clf__estimator__warm_start': masked_array(data=[True, True],\n",
       "              mask=[False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'clf__estimator__multi_class': 'ovr',\n",
       "   'clf__estimator__n_jobs': 2,\n",
       "   'clf__estimator__penalty': 'l2',\n",
       "   'clf__estimator__solver': 'saga',\n",
       "   'clf__estimator__verbose': 1,\n",
       "   'clf__estimator__warm_start': True},\n",
       "  {'clf__estimator__multi_class': 'ovr',\n",
       "   'clf__estimator__n_jobs': 2,\n",
       "   'clf__estimator__penalty': 'elasticnet',\n",
       "   'clf__estimator__solver': 'saga',\n",
       "   'clf__estimator__verbose': 1,\n",
       "   'clf__estimator__warm_start': True}],\n",
       " 'split0_test_score': array([0.27765065,        nan]),\n",
       " 'split1_test_score': array([0.26570048,        nan]),\n",
       " 'split2_test_score': array([0.27848423,        nan]),\n",
       " 'split3_test_score': array([0.26856562,        nan]),\n",
       " 'split4_test_score': array([0.29374364,        nan]),\n",
       " 'mean_test_score': array([0.27682892,        nan]),\n",
       " 'std_test_score': array([0.00981476,        nan]),\n",
       " 'rank_test_score': array([-2147483648, -2147483648])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Test your model\n",
    "Show the accuracy, precision, and recall of the tuned model.  \n",
    "\n",
    "Since this project focuses on code quality, process, and  pipelines, there is no minimum performance metric needed to pass. However, make sure to fine tune your models for accuracy, precision and recall to make your project stand out - especially for your portfolio!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the cv pipeline with GridSearch to make predictions on test data\n",
    "y_pred = cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " score on training dataset: 0.3621706845692198\n",
      "\n",
      " score on test dataset: 0.28181263350625574\n"
     ]
    }
   ],
   "source": [
    "# score on training dataset\n",
    "print(\"\\n score on training dataset:\", cv.score(X_train, y_train))\n",
    "\n",
    "# score on test dataset\n",
    "print(\"\\n score on test dataset:\", cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Try improving your model further. Here are a few ideas:\n",
    "* try other machine learning algorithms\n",
    "* add other features besides the TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipline with different model, support vector machine (SVM)\n",
    "\n",
    "# load data from database\n",
    "engine = create_engine(\"sqlite:///../data/DisasterResponse.db\")\n",
    "connection = engine.connect()\n",
    "query = \"SELECT * FROM DisasterResponse\"  ## limit 1000 WHERE related <> 2\n",
    "df = pd.read_sql(query, connection)\n",
    "connection.close()\n",
    "\n",
    "# Keep only the predictors in the X\n",
    "predictors = [\"message\"]\n",
    "X = df[predictors].message.values\n",
    "print(\"Dimensions of X are:\", X.ndim)\n",
    "print(\"Shape of X is\", X.shape)\n",
    "print(\"Size of X is\", X.size)\n",
    "\n",
    "# keep ony the 35 response variables in y; dropped child_alone since all values are 0\n",
    "y = df.loc[:, ~df.columns.\n",
    "           isin(['id', 'message', 'original', 'genre', 'child_alone'])]\n",
    "y.head()\n",
    "print(\"Dimensions of y are:\", y.ndim)\n",
    "print(\"Shape of y is\", y.shape)\n",
    "print(\"Size of y is\", y.size)\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    # Normalize case and remove punctuation\n",
    "    text = re.sub(r\"[^a-zA-Z0-9]\", \" \", text.lower())\n",
    "\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words and lemmatize\n",
    "    tokens = [w for w in tokens if w not in stopwords.words(\"english\")]\n",
    "\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    clean_tokens = []\n",
    "    for tok in tokens:\n",
    "        clean_tok = lemmatizer.lemmatize(tok).lower().strip()\n",
    "        clean_tokens.append(clean_tok)\n",
    "\n",
    "    return clean_tokens\n",
    "\n",
    "\n",
    "# let's split the data as train test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    train_size=0.75,\n",
    "                                                    random_state=42)\n",
    "\n",
    "# let's check the train test split results\n",
    "print(\"X_train Dim are:\", X_train.ndim, \"Shape=\", X_train.shape, \"Size =\",\n",
    "      X_train.size)\n",
    "print(\"y_train Dim are:\", y_train.ndim, \"Shape=\", y_train.shape, \"Size =\",\n",
    "      y_train.size)\n",
    "print(\"X_test  Dim are:\", X_test.ndim, \"Shape=\", X_test.shape, \"Size =\",\n",
    "      X_test.size)\n",
    "print(\"y_test  Dim are:\", y_test.ndim, \"Shape=\", y_test.shape, \"Size =\",\n",
    "      y_test.size)\n",
    "\n",
    "# Define pipeline for SVC\n",
    "pipeline = Pipeline([('vect', CountVectorizer(tokenizer=tokenize)),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('scaler', StandardScaler()),\n",
    "                     ('svc', MultiOutputClassifier(SVC(gamma='auto')))])\n",
    "\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "print(pipeline.get_params().keys())\n",
    "\n",
    "# parms for pipline with different model\n",
    "parameters = {\n",
    "    'scaler__with_mean': [False],\n",
    "    'svc__estimator__C': [1.0],  # Regularization parameter\n",
    "    'svc__n_jobs':\n",
    "    [2],  # Number of CPU cores used when parallelizing over classes\n",
    "    'svc__estimator__verbose': [1]\n",
    "}\n",
    "# define GridSearchCV\n",
    "cv = GridSearchCV(pipeline, param_grid=parameters)\n",
    "\n",
    "# Fit the pipline with different model\n",
    "import time\n",
    "\n",
    "starttm = time.time()\n",
    "cv.fit(X_train, y_train)\n",
    "endtm = time.time()\n",
    "execTmsec = (endtm - starttm) * 10**6\n",
    "print(\"execution time for the fit=\", execTmsec, \"seconds\")\n",
    "\n",
    "# what are the best parms\n",
    "cv.best_params_\n",
    "\n",
    "# what are the overall results from the new model\n",
    "cv.cv_results_\n",
    "\n",
    "# Use the pipeline with GridSearch to make predictions on test data\n",
    "y_pred = cv.predict(X_test)\n",
    "\n",
    "# score on training dataset\n",
    "print(\"\\n score on training dataset:\", cv.score(X_train, y_train))\n",
    "\n",
    "# score on test dataset\n",
    "print(\"\\n score on test dataset:\", cv.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Export your model as a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_filepath = \"svc_model.pkl\"\n",
    "with open(model_filepath, 'wb') as pklfile:\n",
    "    pickle.dump(cv, pklfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Use this notebook to complete `train.py`\n",
    "Use the template file attached in the Resources folder to write a script that runs the steps above to create a database and export a model based on a new dataset specified by the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
